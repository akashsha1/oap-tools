{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf18f9d1",
   "metadata": {},
   "source": [
    "# Run BERT-Large training workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download datasets, checkpoints and pre-trained model\n",
    "rm -rf ~/TF/bert-large\n",
    "mkdir -p  ~/TF/bert-large/SQuAD-1.1\n",
    "cd ~/TF/bert-large/SQuAD-1.1\n",
    "wget https://github.com/oap-project/oap-project.github.io/raw/master/resources/ai/bert/dev-v1.1.json\n",
    "wget https://github.com/oap-project/oap-project.github.io/raw/master/resources/ai/bert/evaluate-v1.1.py\n",
    "wget https://github.com/oap-project/oap-project.github.io/raw/master/resources/ai/bert/train-v1.1.json\n",
    "\n",
    "cd ~/TF/bert-large\n",
    "wget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/bert_large_checkpoints.zip\n",
    "unzip bert_large_checkpoints.zip\n",
    "\n",
    "cd ~/TF/bert-large\n",
    "wget https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
    "unzip wwm_uncased_L-24_H-1024_A-16.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4464b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# BERT-Large training\n",
    "# Install necessary packages\n",
    "sudo apt-get install -y numactl\n",
    "sudo apt-get install -y libblacs-mpi-dev\n",
    "# Create ckpt directory\n",
    "rm -rf  ~/TF/bert-large/training/*\n",
    "mkdir -p ~/TF/bert-large/training/BERT-Large-output\n",
    "# Download IntelAI benchmark\n",
    "cd ~/TF/bert-large/training\n",
    "wget https://github.com/IntelAI/models/archive/refs/tags/v1.8.1.zip\n",
    "unzip v1.8.1.zip\n",
    "wget https://github.com/oap-project/oap-tools/raw/master/integrations/ml/databricks/benchmark/IntelAI_models_bertlarge_inference_realtime_throughput.patch\n",
    "cd ./models-1.8.1/\n",
    "git apply ../IntelAI_models_bertlarge_inference_realtime_throughput.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#Bert-Large training\n",
    "export SQUAD_DIR=~/TF/bert-large/SQuAD-1.1/\n",
    "export BERT_LARGE_OUTPUT=~/TF/bert-large/training/BERT-Large-output\n",
    "export BERT_LARGE_MODEL=~/TF/bert-large/wwm_uncased_L-24_H-1024_A-16\n",
    "export PYTHONPATH=~/TF/bert-large/training/models-1.8.1/benchmarks/\n",
    "\n",
    "cores_per_socket=$(lscpu | awk '/^Core\\(s\\) per socket/{ print $4 }')\n",
    "numa_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\n",
    "\n",
    "cd ~/TF/bert-large/training/models-1.8.1/benchmarks/\n",
    "\n",
    "function run_training_without_numabind() {\n",
    "     /anaconda/envs/azureml_py38_tensorflow/bin/python launch_benchmark.py \\\n",
    "        --model-name=bert_large \\\n",
    "        --precision=fp32 \\\n",
    "        --mode=training \\\n",
    "        --framework=tensorflow \\\n",
    "        --batch-size=4 \\\n",
    "        --benchmark-only \\\n",
    "        --data-location=$BERT_LARGE_MODEL \\\n",
    "        -- train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_MODEL/bert_config.json   init_checkpoint=$BERT_LARGE_MODEL/bert_model.ckpt     vocab_file=$BERT_LARGE_MODEL/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=0.1     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True\n",
    "    }\n",
    "\n",
    "function run_training_with_numabind() {\n",
    "    intra_thread=`expr $cores_per_socket - 2`\n",
    "    /anaconda/envs/azureml_py38_tensorflow/bin/python launch_benchmark.py \\\n",
    "        --model-name=bert_large \\\n",
    "        --precision=fp32 \\\n",
    "        --mode=training \\\n",
    "        --framework=tensorflow \\\n",
    "        --batch-size=4 \\\n",
    "        --mpi_num_processes=$numa_nodes \\\n",
    "        --num-intra-threads=$intra_thread \\\n",
    "        --num-inter-threads=1 \\\n",
    "        --benchmark-only \\\n",
    "        --data-location=$BERT_LARGE_MODEL \\\n",
    "        --train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_MODEL/bert_config.json init_checkpoint=$BERT_LARGE_MODEL/bert_model.ckpt     vocab_file=$BERT_LARGE_MODEL/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=0.1     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True\n",
    "}\n",
    "          \n",
    "\n",
    "if [ \"$numa_nodes\" = \"1\" ];then\n",
    "        run_training_without_numabind\n",
    "else\n",
    "        run_training_with_numabind\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1102158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Get the trarining result\n",
    "numa_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\n",
    "if [ \"$numa_nodes\" = \"1\" ];then\n",
    "        cd ~/TF/bert-large/training/models-1.8.1/benchmarks/common/tensorflow/logs\n",
    "        cat benchmark*.log | grep \"throughput((num_processed_examples-threshod_examples)/Elapsedtime)\"\n",
    "else\n",
    "        cd /home/azureuser/TF/bert-large/training/models-1.8.1/benchmarks/common/tensorflow/logs/\n",
    "        # Single socket's throught\n",
    "        cat benchmark*.log | grep \"throughput((num_processed_examples-threshod_examples)/Elapsedtime)\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print TensorFlow version, and check whether it is intel-optimized\n",
    "\n",
    "import tensorflow\n",
    "print(\"tensorflow version: \" + tensorflow.__version__)\n",
    "\n",
    "from packaging import version\n",
    "if (version.parse(\"2.5.0\") <= version.parse(tensorflow.__version__)):\n",
    "  from tensorflow.python.util import _pywrap_util_port\n",
    "  print( _pywrap_util_port.IsMklEnabled())\n",
    "else:\n",
    "  from tensorflow.python import _pywrap_util_port\n",
    "  print(_pywrap_util_port.IsMklEnabled())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Tensorflow",
   "language": "python",
   "name": "azureml_py38_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
