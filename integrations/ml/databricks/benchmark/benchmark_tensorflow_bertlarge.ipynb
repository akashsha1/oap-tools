{"cells":[{"cell_type":"code","source":["%sh\n\n# Download datasets, checkpoints and pre-trained model\nrm -rf /dbfs/home/TF/bert-large\nmkdir -p /dbfs/home/TF/bert-large\n\nmkdir -p /dbfs/home/TF/bert-large/SQuAD-1.1\ncd /dbfs/home/TF/bert-large/SQuAD-1.1\nwget https://github.com/oap-project/oap-project.github.io/raw/master/resources/ai/bert/dev-v1.1.json\nwget https://github.com/oap-project/oap-project.github.io/raw/master/resources/ai/bert/evaluate-v1.1.py\nwget https://github.com/oap-project/oap-project.github.io/raw/master/resources/ai/bert/train-v1.1.json\n\ncd /dbfs/home/TF/bert-large\nwget https://storage.googleapis.com/intel-optimized-tensorflow/models/v1_8/bert_large_checkpoints.zip\nunzip bert_large_checkpoints.zip\n\ncd /dbfs/home/TF/bert-large\nwget https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\nunzip wwm_uncased_L-24_H-1024_A-16.zip"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24028691-c8a6-40a1-945d-6449823d20d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import os\nimport subprocess\n\nfrom pathlib import Path\n  \ndef run_training():\n  training = '/tmp/training.sh'\n  with open(training, 'w') as f:\n    f.write(\"\"\"#!/bin/bash\n    # BERT-Large Training\n    # Install necessary package\n    sudo apt-get update\n    sudo apt-get install zip -y\n    sudo apt-get -y install git\n    sudo apt-get install -y libblacs-mpi-dev\n    sudo apt-get install -y numactl\n    \n    # Remove old materials if exist\n    rm -rf /TF/\n    mkdir /TF/\n    # Create ckpt directory\n    mkdir -p /TF/BERT-Large-output/\n    # Download IntelAI benchmark\n    cd /TF/\n    wget https://github.com/IntelAI/models/archive/refs/tags/v1.8.1.zip\n    unzip v1.8.1.zip\n    \n    cores_per_socket=$(lscpu | awk '/^Core\\(s\\) per socket/{ print $4 }')\n    numa_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\n    export SQUAD_DIR=/dbfs/home/TF/bert-large/SQuAD-1.1\n    export BERT_LARGE_MODEL=/dbfs/home/TF/bert-large/wwm_uncased_L-24_H-1024_A-16\n    export BERT_LARGE_OUTPUT=/TF/BERT-Large-output/\n    export PYTHONPATH=$PYTHONPATH:.\n    \n    function run_training_without_numabind() {\n     python launch_benchmark.py \\\n        --model-name=bert_large \\\n        --precision=fp32 \\\n        --mode=training \\\n        --framework=tensorflow \\\n        --batch-size=4 \\\n        --benchmark-only \\\n        --data-location=$BERT_LARGE_MODEL \\\n        -- train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_MODEL/bert_config.json   init_checkpoint=$BERT_LARGE_MODEL/bert_model.ckpt     vocab_file=$BERT_LARGE_MODEL/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=0.1     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True\n    }\n\n    function run_training_with_numabind() {\n      intra_thread=`expr $cores_per_socket - 2`\n      python launch_benchmark.py \\\n        --model-name=bert_large \\\n        --precision=fp32 \\\n        --mode=training \\\n        --framework=tensorflow \\\n        --batch-size=4 \\\n        --mpi_num_processes=$numa_nodes \\\n        --num-intra-threads=$intra_thread \\\n        --num-inter-threads=1 \\\n        --benchmark-only \\\n        --data-location=$BERT_LARGE_MODEL \\\n        -- train-option=SQuAD  DEBIAN_FRONTEND=noninteractive   config_file=$BERT_LARGE_MODEL/bert_config.json init_checkpoint=$BERT_LARGE_MODEL/bert_model.ckpt     vocab_file=$BERT_LARGE_MODEL/vocab.txt train_file=$SQUAD_DIR/train-v1.1.json     predict_file=$SQUAD_DIR/dev-v1.1.json      do-train=True learning-rate=1.5e-5   max-seq-length=384     do_predict=True warmup-steps=0     num_train_epochs=0.1     doc_stride=128      do_lower_case=False     experimental-gelu=False     mpi_workers_sync_gradients=True\n    }\n    \n    # Launch Benchmark for training\n    cd /TF/models-1.8.1/benchmarks/\n    \n    if [ \"$numa_nodes\" = \"1\" ];then\n            run_training_without_numabind\n    else\n            run_training_with_numabind\n    fi \"\"\")\n    \n  os.chmod(training, 555)\n  p = subprocess.Popen([training], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n  directory_to_second_numa_info = Path(\"/sys/devices/system/node/node1\")\n  \n  if  directory_to_second_numa_info.exists():\n    # 2 NUMA nodes\n    for line in iter(p.stdout.readline, ''):\n      if b\"Reading package lists...\" in line or b\"answer: [UNK] 1848\" in line:\n        print(\"\\t\\t\\t\\t  Preparing data ......\", end='\\r')\n      if b\"INFO:tensorflow:examples/sec\" in line:\n        print(\"\\t\\t\\t\\t  Training started, current real-time throughput (examples/sec) : \" + str(float(str(line).strip(\"\\\\n'\").split(' ')[1])*2), end='\\r')\n      if line == b'' and p.poll() != None:\n        break\n  else:\n    # 1 NUMA node\n    for line in iter(p.stdout.readline, ''):\n      if b\"Reading package lists...\" in line or b\"answer: [UNK] 1848\" in line:\n        print(\"\\t\\t\\t\\t  Preparing data ......\", end='\\r')\n      if b\"INFO:tensorflow:examples/sec\" in line:\n        print(\"\\t\\t\\t\\t  Training started, current real-time throughput (examples/sec) : \" + str(line).strip(\"\\\\n'\").split(' ')[1], end='\\r')\n      if line == b'' and p.poll() != None:\n        break\n        \n  p.stdout.close()\n\nrun_training()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48189df1-04ac-4b37-a46c-8affe60d34e6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import os\nimport subprocess\n\nfrom pathlib import Path\n  \ndef run_inference():\n  inference = '/tmp/inference.sh'\n  with open(inference, 'w') as f:\n    f.write(\"\"\"#!/bin/bash\n    # BERT-Large Inference\n    # Install necessary package\n    sudo apt-get update\n    sudo apt-get install zip -y\n    sudo apt-get -y install git\n    sudo apt-get install -y numactl\n    # Remove old materials if exist\n    rm -rf /TF/\n    mkdir /TF/\n    # Create ckpt directory\n    mkdir -p /TF/BERT-Large-output/\n    export BERT_LARGE_OUTPUT=/TF/BERT-Large-output\n    # Download IntelAI benchmark\n    cd /TF/\n    wget https://github.com/IntelAI/models/archive/refs/tags/v1.8.1.zip\n    unzip v1.8.1.zip\n    cd /TF/models-1.8.1/\n    wget https://github.com/oap-project/oap-tools/raw/master/integrations/ml/databricks/benchmark/IntelAI_models_bertlarge_inference_realtime_throughput.patch\n    git apply IntelAI_models_bertlarge_inference_realtime_throughput.patch\n\n    export SQUAD_DIR=/dbfs/home/TF/bert-large/SQuAD-1.1/\n    export BERT_LARGE_DIR=/dbfs/home/TF/bert-large/\n    export PYTHONPATH=$PYTHONPATH:.\n\n    # Launch Benchmark for inference\n    numa_nodes=$(lscpu | awk '/^NUMA node\\(s\\)/{ print $3 }')\n\n    function run_inference_without_numabind() {\n      cd /TF/models-1.8.1/benchmarks/\n      python3 launch_benchmark.py \\\n        --model-name=bert_large \\\n        --precision=fp32 \\\n        --mode=inference \\\n        --framework=tensorflow \\\n        --batch-size=32 \\\n        --data-location $BERT_LARGE_DIR/wwm_uncased_L-24_H-1024_A-16 \\\n        --checkpoint $BERT_LARGE_DIR/bert_large_checkpoints \\\n        --output-dir $BERT_LARGE_OUTPUT/bert-squad-output \\\n        --verbose \\\n        -- infer_option=SQuAD \\\n           DEBIAN_FRONTEND=noninteractive \\\n           predict_file=$SQUAD_DIR/dev-v1.1.json \\\n           experimental-gelu=False \\\n           init_checkpoint=model.ckpt-3649\n    }\n\n    function run_inference_with_numabind() {\n      cd /TF/models-1.8.1/benchmarks/\n      nohup python3 launch_benchmark.py \\\n        --model-name=bert_large \\\n        --precision=fp32 \\\n        --mode=inference \\\n        --framework=tensorflow \\\n        --batch-size=32 \\\n        --socket-id 0  \\\n        --data-location $BERT_LARGE_DIR/wwm_uncased_L-24_H-1024_A-16 \\\n        --checkpoint $BERT_LARGE_DIR/bert_large_checkpoints \\\n        --output-dir $BERT_LARGE_OUTPUT/bert-squad-output \\\n        --verbose \\\n        -- infer_option=SQuAD \\\n           DEBIAN_FRONTEND=noninteractive \\\n           predict_file=$SQUAD_DIR/dev-v1.1.json \\\n           experimental-gelu=False \\\n           init_checkpoint=model.ckpt-3649 >> socket0-inference-log &\n\n       python3 launch_benchmark.py \\\n        --model-name=bert_large \\\n        --precision=fp32 \\\n        --mode=inference \\\n        --framework=tensorflow \\\n        --batch-size=32 \\\n        --socket-id 1 \\\n        --data-location $BERT_LARGE_DIR/wwm_uncased_L-24_H-1024_A-16 \\\n        --checkpoint $BERT_LARGE_DIR/bert_large_checkpoints \\\n        --output-dir $BERT_LARGE_OUTPUT/bert-squad-output \\\n        --verbose \\\n        -- infer_option=SQuAD \\\n           DEBIAN_FRONTEND=noninteractive \\\n           predict_file=$SQUAD_DIR/dev-v1.1.json \\\n           experimental-gelu=False \\\n           init_checkpoint=model.ckpt-3649\n    }\n\n    if [ \"$numa_nodes\" = \"1\" ];then\n            run_inference_without_numabind\n    else\n            run_inference_with_numabind\n    fi\"\"\")\n    \n  os.chmod(inference, 555)\n  p = subprocess.Popen([inference], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n  directory_to_second_numa_info = Path(\"/sys/devices/system/node/node1\")\n\n  \n  if  directory_to_second_numa_info.exists():\n    # 2 NUMA nodes\n    for line in iter(p.stdout.readline, ''):\n      if b'Reading package lists...' in line or b'INFO:tensorflow:tokens' in line or b'INFO:tensorflow:  name = bert' in line:\n        print(\"\\t\\t\\t\\t  Preparing data ......\", end='\\r')\n      if b\"INFO:tensorflow:examples/sec\" in line:\n        print(\"\\t\\t\\t\\t  Inference started, current real-time throughput (examples/sec) : \" + str(float(str(line).strip(\"\\\\n'\").split(' ')[1])*2), end='\\r')\n      if b\"throughput((num_processed_examples-threshod_examples)/Elapsedtime)\" in line:\n        print(\"\\t\\t\\t\\t  Inference finished, overall inference throughput (examples/sec) : \" + str(float(str(line).strip(\"\\\\n'\").split(':')[1])*2), end='\\r')\n      if line == b'' and p.poll() != None:\n        break\n  else:\n    # 1 NUMA node\n    for line in iter(p.stdout.readline, ''):\n      if b'Reading package lists...' in line or b'INFO:tensorflow:tokens' in line or b'INFO:tensorflow:  name = bert' in line:\n        print(\"\\t\\t\\t\\t  Preparing data ......\", end='\\r')\n      if b\"INFO:tensorflow:examples/sec\" in line:\n        print(\"\\t\\t\\t\\t  Inference started, current real-time throughput (examples/sec) : \" + str(line).strip(\"\\\\n'\").split(' ')[1], end='\\r')\n      if b\"throughput((num_processed_examples-threshod_examples)/Elapsedtime)\" in line:\n        print(\"\\t\\t\\t\\t  Inference finished, overall inference throughput (examples/sec) : \" + str(line).strip(\"\\\\n'\").split(':')[1], end='\\r')\n      if line == b'' and p.poll() != None:\n        break\n       \n  p.stdout.close()\n  \nrun_inference()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c88e041c-0634-40d0-9f76-b1d39f910c89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Print version, and check whether is intel-optimized\nimport tensorflow\nprint(\"tensorflow version: \" + tensorflow.__version__)\n\nfrom packaging import version\nif (version.parse(\"2.5.0\") <= version.parse(tensorflow.__version__)):\n  from tensorflow.python.util import _pywrap_util_port\n  print( _pywrap_util_port.IsMklEnabled())\nelse:\n  from tensorflow.python import _pywrap_util_port\n  print(_pywrap_util_port.IsMklEnabled())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a2eaedb-cf21-4c29-928b-ee4716c8ad20"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"benchmark_tensorflow_bertlarge","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2866140108339648}},"nbformat":4,"nbformat_minor":0}
